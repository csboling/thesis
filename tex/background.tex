\documentclass[../thesis]{subfiles}
\begin{document}

\chapter{Background}

A growing body of work in the field of meta-research has identified a
number of obstructions to research reproducibility and possible
techniques for improving the trustworthiness of scientific
publications. One promising approach for addressing some of these
factors is the widespread adoption of standardized procedures for
experiment design, record keeping, and publication, supported wherever
possible by software tools for automation and research lifecycle
management. This chapter identifies the functional requirements of a
software system for designing and executing complex experiments and
organizing their results and justifies the need for a next-generation
collaborative lab information management system. We briefly describe
the electrochemical sensor research which produced our group's need
for the software, analyze the tooling requirements of our project, and
then explore the existing ecosystem of software tools for automation
and curation of research.



\section{Use case: Electrochemical sensor arrays}

Our development of a next-generation collaborative \gls{LIMS} is motivated
by a concrete research task, namely characterization and design of
electrochemical sensor arrays for precise concentration estimation of
a broad range of chemical targets \cite{Li2014, Wang2016,
  Wang2014}. Electrochemical sensors are sensitive to a number of
interacting environmental conditions such as temperature, humidity,
ambient airflow, and presence of trace interferent chemicals
\cite{Marco2012}. The sensitivity of a given sensor to a particular analyte compound is also
a complex function of device geometry, electrolyte and substrate
materials, and applied electrical stimulus. In order to make
measurements meaningful, as much of this secondary information as
possible must be collated with the raw electrical output of the
sensors. Additionally, a typical characterization experiment involves
a sequence of manipulations of controllable parameters such as the
flow rates of input gases or applied voltage waveforms. The end
engineering goal of these experiments is to determine the inverse
function mapping each sensor's instantaneous output current, input
voltage, and observable environmental parameters into a concentration
profile of the device's chemical environment. For an experimental data
set to afford such an analysis, the input conditions should be
controlled as accurately as possible, and especially for batteries of
tests involving many sensors operating in tandem it is necessary to
employ computer control to achieve uniform results.

This experimental scenario, depicted schematically in figure
\ref{fig:EchemUseCase},
will serve as a running example to demonstrate the
capabilities and requirements of the software tool described by this
thesis. Our ideal experimental setup involves commercial lab equipment
as well as custom data acquisition hardware, simultaneous operation of
many sensors with different physical characteristics, and precisely
timed computer choreography of electrical interrogation protocols and
gas flow rates. Furthermore, the exact nature of the experiments being
run changes frequently as researchers identify new questions, design
new sensors, and involve new equipment in their work,
requiring our control and data management software to grow with the
changing requirements of its users.

We believe that a software framework capable of scheduling and
autonomously executing experiments of this level of complexity has the
potential to be more broadly useful in any scientific environment with
similar workflow needs.
The design goals of our software package are enumerated in the
following section, followed by an overview of the existing tools which
fulfill some of these requirements.

\begin{figure}
  \caption{Example experimental apparatus for characterizing an array
    of electrochemical gas sensors. \label{fig:EchemUseCase}}
\end{figure}


\section{Requirements and Terminology}


\subsection{Automation}
A primary motivator

\subsection{Metadata and data provenance}
In many cases, drawing conclusions about a data set relies on
metadata and information about experimental conditions that is
difficult to acquire for every trial and is not obviously
relevant at the outset, forcing researchers to backtrack and repeat
work in order to be confident in their results. Examples of
metadata which are often omitted from raw data sets include
measurement units, input conditions, sample and equipment IDs, and
annotations such as the hypothesis of an experiment or where to find
more information.



\subsection{Collaboration}



\subsection{User Compliance}
A known challenge faced when developing software for reproducible research
is that feature-rich tools often present users with a substantial
learning curve, deterring widespread adoption.



\subsection{Extensibility}



\section{Review of existing experiment management software}

The complex needs of modern research have created a large specialized
software market, and there are now dozens of tools for computerizing
various laboratory management and research tasks. There are now many
companies offering lab informatics software with a broad range of
capabilities,

Since many of these programs are proprietary, it is difficult to
compare their feature sets precisely.



\subsection{Electronic lab notebooks}

An \gls{ELN} is a software tool for helping
researchers to chronicle their day-to-day investigations and
results. Several surveys of commercially available ELNs have been
published \cite{Rubacha2011, }, but the domain is still evolving
rapidly and many of these programs have begun to integrate
capabilities for experiment specification and execution.

Many general-purpose programming language environments targeted toward
scientific computing include electronic lab notebook functionality.
These tools are typically environments for literate programming
\cite{Knuth:1984:LP:473.479} which are able to embed plots and data
tables alongside code and natural language documentation. Popular
solutions in this domain include Mathematica \cite{mathematica},
R \cite{Rlang}, IPython/Jupyter \cite{IPython}, and
MATLAB Notebook \cite{MATLAB}.

Typically commercial products in this domain offer users compliance
with the FDA's recommendation on electronic recordkeeping \cite{FDA}



\subsection{\gls{LIMS}}
A laboratory information management system (\gls{LIMS})

Some of these software packages provide a means of specifying
experiment procedures and many of them integrate with an electronic
lab notebook, but

A modern \gls{LIMS} provides a

Many of these tools are essentially glorified Wiki packages

In particular, Agilent's OpenLAB suite (formerly Kalabie) offers a
notebook tool which combines data collection, storage, analysis, and
collaboration capabilities. This package is also capable of
integrating with data collected from instruments manufactured by
Agilent and some of its business partners. The tool appears to provide
many of the capabilities found in a typical \gls{LIMS} combined with some
support for real-time hardware control,
 still lacks modularity, user-customizability, version control




\subsection{Workflow design tools}

Defining, composing, and documenting complex procedures is a core
organizational need of many research groups. A number of so-called
\glspl{workflowMgmt} have emerged to help manage task schedules and
dependencies in domains such as manufacturing
\cite{Allweyer:2010:BPM:1841147}, high performance computing
\cite{VisTrails}, and business management
\cite{cardoso2004workflow}. Workflow editors provide users with a
means of constructing executable tasks by describing how
data moves through them, typically by visually manipulating a directed
graph of processes. In some cases workflows may serve purely as
documentation, while workflow tools for \gls{insilico} science
are often executable and may be bundled with data to provide direct
replication of analysis flows on other machines. The most prominent
examples of workflow software
targeted toward scientists are built to facilitate the design and
execution of high performance computing simulations such as Apache
Taverna \cite{Taverna} and VisTrails \cite{VisTrails}. Less
attention has paid to scientific processes that are not completely digital
and are therefore harder to fully automate. The application
of similar software to managing business processes and software
development suggests that these tools may also be valuable aids for
describing complicated scientific experiments, and some \gls{LIMS} packages
provide some of this functionality \cite{CoreLIMS}. By combining these
workflow specification tools with software for controlling lab
equipment, it may be possible to provide domain scientists with a
powerful framework for defining executable specifications of
complicated laboratory procedures.

A related class of software reproducibility tools encourages users to
bundle input sets and sequences of data-transforming programs into a
single distributable file intended to accompany published results.
A notable example is \cite{ReproZip}, which uses virtual machines to
produce self-contained computing environments for reproducing digital
analysis under identical conditions on different physical
computers. ReproZip automatically determines all the files necessary
for replicating an \gls{insilico} workflow by monitoring the operating
system during ordinary task execution. These techniques offer a
promising strategy for improving scientists' ability to capture the
intricacies of their work for later review or reuse while avoiding
excessive demands on the user's discipline.

Industry groups have also made several attempts to produce
standardized data models for business processes and equipment, perhaps
the most popular of which is \gls{BPMN}
\cite{Allweyer:2010:BPM:1841147}, typically represented by a directed
graph or flowchart much like the data models used in scientific
workflow software. The
most full-featured model expanding on this concept is ISO 15926
\cite{West2009}. This model promises
a level of generality that is sufficient to enable interoperability
between businesses in different sectors and countries which rely on
large, varied sets of equipment and software. The still-growing
specification encompasses information as diverse as process
specification and refinement, structural description of organizations
and devices, component lifecycle information and more. ISO 15926's
representation format is based on semantic web technologies such as OWL, which
employs a graph model to describe semantic relationships between
entities, where each entity and relationship has an associated
hyperlink. The standard has been under development for 25 years, but
many specification documents have yet to be published and no software
implementations are currently freely available. The extreme complexity
of the model is also an impediment to adoption by end users as well as
implementation.



\subsection{Equipment automation tools}

To extend automation of scientific processes beyond the purely
computational domain, several vendors offer tools for coordinating
simultaneous operation of actuators and data acquisition modules.
Likely the most visible software package providing this functionality
is National Instruments LabVIEW \cite{ELLIOTT2007}
LabVIEW's G visual programming language allows users to connect
devices, signal processing blocks, and graphical interface elements,
ultimately building a custom front panel and controller for a
``virtual instrument'' which may communicate with many different
pieces of lab equipment. LabVIEW interacts with National Instruments'
line of data acquisition and control hardware and also ships with a
large library of drivers for scientific instruments produced by many
vendors.

, and arguably has much in common
with some workflow editors.

Other software toolkits have begun to capitalize on
the recent emergence of affordable network-connected microcontrollers
and single-board computers.
ZettaJS intends to provide a hardware abstraction layer for
controlling and coordinating embedded data acquisition platforms over
the web \cite{ZettaJS}.


Unfortunately, relatively few \gls{LIMS} vendors incorporate equipment
automation into their feature sets.



\section{Rich publication data models}

\subsection{Research objects}







\section{Summary}

A number of software tools for automating data collection, analyzing
and comparing data sets, and interdisciplinary scientific
collaboration have emerged in recent years. Moving toward an    will
require the convergence of \gls{LIMS} software with equipment automation .
Many commercial \gls{LIMS} are also inadequately flexible to researchers'
rapidly changing data organization requirements

\end{document}

%%% Local Variables: ***
%%% mode:latex ***
%%% TeX-master: "../thesis.tex"  ***
%%% End: ***